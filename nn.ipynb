{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************\n",
      "***************************\n",
      "Preparing training and test sets...\n",
      "Training set: 52428 elements 80% of data\n",
      "Example: [([0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0], [1, 1, 0, 1, 0, 0, 0, 1]), ([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0], [1, 1, 0, 1, 0, 1, 1, 1])]\n",
      "Test set: 13108 elements 20% of data\n",
      "Example: [([1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0], [0, 1, 1, 0, 0, 0, 1, 0]), ([1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0], [0, 0, 1, 1, 1, 0, 1, 1])]\n",
      "***************************\n",
      "***************************\n",
      "Learning...\n",
      "epoch 0: 9948.507207532135 9948.4912109375\n",
      "epoch 1: 2649.5027213335034 2649.50341796875\n",
      "epoch 2: 1562.4169950274309 1562.4158935546875\n",
      "epoch 3: 1109.2126767858824 1109.2138671875\n",
      "epoch 4: 860.0207378580659 860.0198364257812\n",
      "epoch 5: 702.3251338308934 702.3240966796875\n",
      "epoch 6: 593.5383603645532 593.5364379882812\n",
      "epoch 7: 513.9593043121256 513.9594116210938\n",
      "epoch 8: 453.2165643600795 453.2164001464844\n",
      "epoch 9: 405.3296078612482 405.32843017578125\n",
      "epoch 10: 366.60736341610294 366.6080017089844\n",
      "epoch 11: 334.6483310970315 334.65032958984375\n",
      "epoch 12: 307.82264372655493 307.8233642578125\n",
      "epoch 13: 284.98519796094183 284.98504638671875\n",
      "epoch 14: 265.30790622252687 265.30621337890625\n",
      "epoch 15: 248.17709587919836 248.17788696289062\n",
      "epoch 16: 233.12833259119185 233.1287078857422\n",
      "epoch 17: 219.803654940983 219.8046417236328\n",
      "epoch 18: 207.92271723484527 207.92388916015625\n",
      "epoch 19: 197.2628348282209 197.2634735107422\n",
      "epoch 20: 187.64488454922312 187.6458740234375\n",
      "epoch 21: 178.92314938110846 178.9239501953125\n",
      "epoch 22: 170.9778775024155 170.9795379638672\n",
      "epoch 23: 163.70974537845404 163.70970153808594\n",
      "epoch 24: 157.03567973881454 157.03651428222656\n",
      "epoch 25: 150.88566465175097 150.88726806640625\n",
      "epoch 26: 145.20027296764306 145.2006378173828\n",
      "epoch 27: 139.92873739460464 139.92970275878906\n",
      "epoch 28: 135.02742841991432 135.02764892578125\n",
      "epoch 29: 130.45864236452007 130.45875549316406\n",
      "epoch 30: 126.18962826875529 126.19015502929688\n",
      "epoch 31: 122.1918004461204 122.19275665283203\n",
      "epoch 32: 118.44009664952928 118.44094848632812\n",
      "epoch 33: 114.91245137506611 114.91378784179688\n",
      "epoch 34: 111.58936090585601 111.5902099609375\n",
      "epoch 35: 108.4535219792172 108.45582580566406\n",
      "epoch 36: 105.48952993688545 105.49095153808594\n",
      "epoch 37: 102.68362523894726 102.6845474243164\n",
      "epoch 38: 100.0234795359074 100.0250473022461\n",
      "epoch 39: 97.49801427908453 97.49935150146484\n",
      "epoch 40: 95.09724623806204 95.09822845458984\n",
      "epoch 41: 92.81215538078924 92.81383514404297\n",
      "epoch 42: 90.63457142850004 90.63629150390625\n",
      "epoch 43: 88.55707607664671 88.55854797363281\n",
      "epoch 44: 86.57291841457955 86.57365417480469\n",
      "epoch 45: 84.6759415110661 84.6771469116211\n",
      "epoch 46: 82.8605184828842 82.86161804199219\n",
      "epoch 47: 81.1214966474064 81.1224365234375\n",
      "epoch 48: 79.45414859120355 79.45560455322266\n"
     ]
    }
   ],
   "source": [
    "import typing as t\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "THRESHOLD = 1e-10\n",
    "NUM_BITS = 8\n",
    "n_inputs = 2 * NUM_BITS + 1\n",
    "n_outputs = NUM_BITS\n",
    "\n",
    "\n",
    "w = np.random.randn(n_inputs, n_outputs) * 0.03\n",
    "bias = np.random.randn(n_outputs, 1) * 0.001\n",
    "\n",
    "wt = torch.tensor(w, requires_grad=True, dtype=torch.float32)\n",
    "bt = torch.tensor(bias, requires_grad=True, dtype=torch.float32)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "\n",
    "print(\"***************************\")\n",
    "print(\"***************************\")\n",
    "print(\"Preparing training and test sets...\")\n",
    "all_inputs = []\n",
    "for x1 in range(1 << NUM_BITS):\n",
    "    for x2 in range(1 << NUM_BITS):\n",
    "        for io, o in enumerate([\"and\"]):\n",
    "            x = []\n",
    "            for i in range(NUM_BITS):\n",
    "                if (x1 & (1 << i)) != 0:\n",
    "                    x.append(1)\n",
    "                else:\n",
    "                    x.append(0)\n",
    "            for i in range(NUM_BITS):\n",
    "                if (x2 & (1 << i)) != 0:\n",
    "                    x.append(1)\n",
    "                else:\n",
    "                    x.append(0)\n",
    "            x.append(io)\n",
    "            y = eval(f\"{x1} {o} {x2}\")\n",
    "            yf = []\n",
    "            for i in range(NUM_BITS):\n",
    "                if (y & (1 << i)) != 0:\n",
    "                    yf.append(1)\n",
    "                else:\n",
    "                    yf.append(0)\n",
    "\n",
    "            all_inputs.append((x, yf))\n",
    "\n",
    "np.random.shuffle(all_inputs)\n",
    "n1 = int(0.8 * len(all_inputs))\n",
    "\n",
    "training_set = all_inputs[:n1]\n",
    "test_set = all_inputs[n1:]\n",
    "print(f\"Training set: {len(training_set)} elements 80% of data\\nExample: {training_set[:2]}\")\n",
    "print(f\"Test set: {len(test_set)} elements 20% of data\\nExample: {test_set[:2]}\")\n",
    "\n",
    "def forward(x: np.array) -> np.array:\n",
    "    z = np.add(np.matmul(np.transpose(w), x), bias)\n",
    "    y = 1.0 / (1.0 + np.exp(-z))\n",
    "    y = np.clip(y, THRESHOLD, 1 - THRESHOLD)\n",
    "    return y\n",
    "\n",
    "def lossf(y: np.array, y_hat: np.array) -> np.float32:\n",
    "    return -np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)) / np.size(y)\n",
    "\n",
    "\n",
    "def back(y: np.array, y_hat: np.array, x: np.array) -> t.Tuple[np.array, np.array]:\n",
    "    \"\"\"Returns derivatives for W and bias\"\"\"\n",
    "    return np.transpose(y_hat - y) * np.array(x) / NUM_BITS, (y_hat - y) / NUM_BITS\n",
    "\n",
    "\n",
    "def update_params(dw: np.array, db: np.array, lr: float) -> None:\n",
    "    global w\n",
    "    global bias\n",
    "    w = w - lr * dw\n",
    "    bias = bias - lr * db\n",
    "\n",
    "\n",
    "LEARNING_RATE = 0.01\n",
    "batch_size = 64\n",
    "batch_start = 0\n",
    "epoch_loss = []\n",
    "\n",
    "print(\"***************************\")\n",
    "print(\"***************************\")\n",
    "print(\"Learning...\")\n",
    "for epoch in range(1000):\n",
    "    sum_loss = 0\n",
    "    sum_loss_t = 0\n",
    "\n",
    "    for bs in range(0, len(training_set), batch_size):\n",
    "        dw = None\n",
    "        db = None\n",
    "        first = True\n",
    "        if wt.grad is not None:\n",
    "            wt.grad.zero_()\n",
    "            bt.grad.zero_()\n",
    "\n",
    "        for sample_x, sample_y in training_set[batch_start:batch_start+batch_size]:\n",
    "            xs = np.array(sample_x)[:, np.newaxis]\n",
    "            ys = np.array(sample_y)[:, np.newaxis]\n",
    "            y_hat = forward(xs)\n",
    "            this_loss = lossf(ys, y_hat)\n",
    "            sum_loss += this_loss\n",
    "            cur_dw, cur_db = back(ys, y_hat, xs)\n",
    "            if first:\n",
    "                dw = cur_dw\n",
    "                db = cur_db\n",
    "                first = False\n",
    "            else:\n",
    "                dw += cur_dw\n",
    "                db += cur_db\n",
    "            outputs = torch.sigmoid(torch.t(wt) @ torch.from_numpy(xs.astype(np.float32)) + bt)\n",
    "            loss = criterion(outputs, torch.from_numpy(ys.astype(np.float32)))\n",
    "            sum_loss_t += loss\n",
    "            loss.backward()\n",
    "\n",
    "        update_params(dw, db, LEARNING_RATE)\n",
    "        wt.data -= LEARNING_RATE * wt.grad\n",
    "        bt.data -= LEARNING_RATE * bt.grad\n",
    "    # if epoch == 0:\n",
    "    print(f\"epoch {epoch}: {sum_loss} {sum_loss_t}\")\n",
    "    epoch_loss.append(sum_loss)\n",
    "\n",
    "\n",
    "def deconstruct(xs, ys, y_hat) -> t.Tuple[int, str, int, int, int, int]:\n",
    "    x1 = 0\n",
    "    x2 = 0\n",
    "    y = 0\n",
    "    ry = 0\n",
    "    p2 = 1\n",
    "    errors_in_bits = 0\n",
    "    if xs[-1]:\n",
    "        o = \"and\"\n",
    "    else:\n",
    "        o = \"or\"\n",
    "    for i in range(NUM_BITS):\n",
    "        if xs[i]:\n",
    "            x1 += p2\n",
    "        if xs[i + NUM_BITS]:\n",
    "            x2 += p2\n",
    "        turn1 = False\n",
    "        turn2 = False\n",
    "        if ys[i]:\n",
    "            turn1 = True\n",
    "            y += p2\n",
    "        if y_hat[i] > 0.5:\n",
    "            turn2 = True\n",
    "            ry += p2\n",
    "        if turn1 != turn2:\n",
    "            errors_in_bits += 1\n",
    "        p2 = 2 * p2\n",
    "    return x1, o, x2, y, ry, errors_in_bits\n",
    "\n",
    "\n",
    "print(\"***************************\")\n",
    "print(\"***************************\")\n",
    "print(\"Testing the network...\")\n",
    "count_wrong = 0\n",
    "count_right = 0\n",
    "count_wrong_t = 0\n",
    "count_right_t = 0\n",
    "errors_in_bits = [0] * (NUM_BITS + 1)\n",
    "errors_in_bits_t = [0] * (NUM_BITS + 1)\n",
    "for sample_x, sample_y in test_set:\n",
    "    xs = np.array(sample_x)[:, np.newaxis]\n",
    "    ys = np.array(sample_y)[:, np.newaxis]\n",
    "    y_hat = forward(xs)\n",
    "    outputs = torch.sigmoid(torch.t(wt) @ torch.from_numpy(xs.astype(np.float32)) + bt)\n",
    "\n",
    "    y_hat = np.round(y_hat)\n",
    "    output = torch.round(outputs)\n",
    "    x1, o, x2, exp_y, real_y, bits = deconstruct(sample_x, sample_y, y_hat)\n",
    "    errors_in_bits[bits] += 1\n",
    "    if torch.equal(torch.from_numpy(np.array(sample_y).astype(np.float64)), torch.from_numpy(np.transpose(y_hat)).squeeze()):\n",
    "        assert exp_y == real_y\n",
    "        count_right += 1\n",
    "    else:\n",
    "        assert exp_y != real_y\n",
    "        count_wrong += 1\n",
    "\n",
    "    x1, o, x2, exp_y, real_y, bits = deconstruct(sample_x, sample_y, output)\n",
    "    errors_in_bits_t[bits] += 1\n",
    "\n",
    "    if torch.equal(torch.from_numpy(np.array(sample_y).astype(np.float64)), torch.transpose(output, 0, 1).squeeze()):\n",
    "        count_right_t += 1\n",
    "    else:\n",
    "        count_wrong_t += 1\n",
    "\n",
    "percent = round((100 * count_right) / (count_right + count_wrong))\n",
    "print(f\"Total wrong = {count_wrong} {count_wrong_t}\")\n",
    "print(f\"Total right = {count_right} {count_right_t}\")\n",
    "print(f\"{percent=}%\")\n",
    "print(f\"{errors_in_bits=} {errors_in_bits_t=}\")\n",
    "\n",
    "plt.plot(epoch_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-06-16T13:04:15.694625Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
